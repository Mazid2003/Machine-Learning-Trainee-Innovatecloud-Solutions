📅 Day 18 – Optimization Techniques in Deep Learning
🎯 Learning Objectives
By the end of this notebook or document, you will:
✅ Understand optimization in machine learning.
✅ Learn about loss functions and their role.
✅ Explore basic to advanced optimization algorithms (SGD, Momentum, RMSProp, Adam).
✅ Grasp challenges like local minima, saddle points, and vanishing gradients.
✅ Understand adaptive learning rate methods.
✅ Learn how to apply learning rate schedules, early stopping, and initialization techniques.

1️⃣ What is Optimization in ML?
👉 Optimization is the process of adjusting model parameters (weights & biases) to minimize the loss function.

The goal is to find:
